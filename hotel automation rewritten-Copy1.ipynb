{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_core.runnables import RunnableParallel,RunnablePassthrough\n",
    "from langchain.output_parsers import PydanticOutputParser,OutputFixingParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_community.llms import OpenAI\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Two Classes\n",
    "\n",
    "We have 2 OpenAI class instances, called llm and llm3. We have a API key, with which we can use either 3.5 or 4. As one can see we have defined our model ot be 3.5. The last variable we need to define is temprature. In simpler terms, the temperature parameter in language models (like LLMs) controls how creative or predictable their responses are. When the temperature is high (closer to 1), the model generates imaginative but less precise answers. When it’s low (close to 0), the model becomes more focused and deterministic. The right balance depends on the task: low temperature for factual answers, high temperature for creative tasks like storytelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(openai_api_key=\"xyz\",model=\"gpt-3.5-turbo-0125\",temperature=0,model_kwargs={\"response_format\": { \n",
    "      \"type\": \"json_object\" \n",
    "    }})\n",
    "\n",
    "llm3=ChatOpenAI(openai_api_key=\"xyz\",model=\"gpt-3.5-turbo-0125\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the script number. This script number will be later used to get a specific input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER THE SCRIPT NUMBER: 42\n"
     ]
    }
   ],
   "source": [
    "filenum=input(\"ENTER THE SCRIPT NUMBER: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining The Class\n",
    "So we make use of the pydantic library we define a class called descriptions which makes use of Base Model, So now we can define our vairables inside this description class. \n",
    "\n",
    "As you can see the first variable that we define is the response variable which is of string formal. Using the Field feature we can add additional metdata( or in simpler words be more specific) about what we want from our response variable. Over here it is validated using the sentence \"description which is re rewritten\". This means down the line when we encounter this class, we can validate if the generated content is the one which we want or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Description(BaseModel):\n",
    "    response: str = Field(description=\" description which is rewritten\")\n",
    "\n",
    "description_parser=PydanticOutputParser(pydantic_object=Description)\n",
    "description_output_parser=OutputFixingParser(parser=description_parser,llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 levels of prompts over here, first the description_writer_prompt, then the anti_ai_detection_prompt, seo_prompt. Each prompt has its own unieq purpose on the prompt. \n",
    "\n",
    "The first level of our prompt asks the LLM to create generic descriptions within in 250 words. The description will be of a hotel that we feed in via the placeholder {inp}. The format description is something which is already described below. \n",
    "\n",
    "The second level of our prompt takes in the input given out by the first run and gives its own output. This description makes sure our conten generated does not seem AI generated. Over here the ipnut variable is in the placeholder called description.\n",
    "\n",
    "The third level of our prompt is called the SEO prompt. It creates SEO(search engine optimised) descriptions of the hotel. It mainly focused on the burstiness of the sentences to make them seem even less AI generated. They can be seen by the input output examples that the user has provided in the prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_writer_prompt=\"\"\"\n",
    "Your task is to create generic descriptions . Each description must be within 250 words. These descriptions should be versatile enough to apply to multiple hotels without mentioning specific names or locations. \n",
    "\n",
    "The target audience is a general group of potential guests. Focus on highlighting each hotel's unique features, amenities, and experiences to entice readers. \n",
    "Ensure the descriptions are clear, concise, and free from content that could lead to plagiarism claims. Put emphasis on any metrics like distance from airport or distance from key tourist locations and include them in your rewritten description. \n",
    "By capturing the essence of each hotel, the goal is to enable potential guests to envision their stay and make informed booking decisions.  \n",
    "\n",
    "Be concise and stick to the point.  \n",
    "\n",
    "The Description to be rewritten is {inp}.\n",
    "\n",
    "JSON {format_instructions}\n",
    "\"\"\"\n",
    "description_writer_template=PromptTemplate(input_variables=[\"inp\"],template\n",
    "=description_writer_prompt,partial_variables={'format_instructions':description_output_parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_ai_detection_prompt=\"\"\"\n",
    "Compose an engaging and original piece of writing showcasing the remarkable capabilities of natural language generation. \n",
    "The word count should be 250 words at a maximum.\n",
    "Craft the content with utmost creativity to ingeniously avoid predictable patterns commonly associated with AI-generated text, \n",
    "ensuring it maintains the authenticity of human composition in English UK.  \n",
    "When it comes to writing content, two factors are crucial, \"perplexity\" and \"burstiness.\" Perplexity measures the complexity of text.\n",
    "Separately, burstiness compares the variations of sentences. Humans tend to write with greater burstiness, for example, with some longer or complex sentences alongside shorter ones. \n",
    "AI sentences tend to be more uniform. Your challenge is to create a captivating text, rich in perplexity and burstiness.\n",
    "This limitation will test your ability to wield language proficiency effectively without triggering AI content detectors. \n",
    "Description to be rewritten is: {description} \n",
    "\n",
    "JSON {format_instructions}\n",
    "\"\"\"\n",
    "anti_ai_detection_template=PromptTemplate(input_variables=[\"description\"],template=anti_ai_detection_prompt,partial_variables={'format_instructions':description_output_parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seo_prompt=\"\"\"\n",
    "Write SEO-friendly and optimized hotel descriptions for a series of hotels. Each description should include the exact phrases \"{hotel_name} room prices\" and \"Book {hotel_name} Online\". \n",
    "Highlight how each hotel offers affordable accommodations suitable for a variety of people and make sure to include the phrases \"{hotel_name} room prices\" and \"Book {hotel_name} Online\" word for word during this part.\n",
    "Mention the hotel address which is {address} somewhere in the description so our customers can reach it easier.\n",
    "Change at least 20 words to other words with the same meaning.\n",
    "The SEO friendly text should have high perplexity and burstiness.Perplexity measures the complexity of text.\n",
    "Separately, burstiness compares the variations of sentences. Humans tend to write with greater burstiness, for example, with some longer or complex sentences alongside shorter ones. \n",
    "AI sentences tend to be more uniform. \n",
    "\n",
    "Example input output pairs as below:\n",
    "1)Input: The zebra ran away from the predators. It was fast and smart. It got to the water and swam. It was safe and happy.\n",
    "Output: The zebra galloped across the savanna, dodging the lions and hyenas that were chasing it. It reached the river and jumped in, hoping to escape. But it was too late. The crocodiles were waiting for it, ready to snap their jaws.\n",
    "\n",
    "2)Input: She saw him at the door with flowers. He said, “I love you.” She was happy and hugged him. She did not see the knife.\n",
    "Output: She opened the door and saw him standing there, holding a bouquet of roses. He smiled and said, “Happy anniversary, my love.” She felt a surge of joy and hugged him. Then she noticed the blood on his shirt and the knife in his hand.\n",
    "\n",
    "3)Input: He had a machine that could do things. He wanted to use it for good and bad. He pushed a button and went somewhere. He was gone.\n",
    "Output: He was a genius, but also a madman. He had invented a device that could manipulate time and space. He wanted to use it to explore the mysteries of the universe, but also to change history. He pressed a button and disappeared, never to be seen again.\n",
    "\n",
    "4)Input: She wanted to be a singer. She practiced a lot and tried hard. She got a chance to sing on TV. She sang well.\n",
    "Output: She had always dreamed of becoming a singer. She practiced every day, sang in every audition, and worked hard to improve her skills. She finally got her big break when she was invited to perform on a popular TV show. She opened her mouth and nothing came out.\n",
    "\n",
    "\n",
    "The description which has to be SEO optimized and whom's perplexity and burstiness needs to be changed is: {anti_ai}\n",
    "\n",
    "JSON {format_instructions}\n",
    "\"\"\"\n",
    "seo_template=PromptTemplate(input_variables=[\"address\",\"hotel_name\",\"anti_ai\"],template=seo_prompt,partial_variables={'format_instructions':description_output_parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the input csv file that we give in has 3 main inputs, one is the hotel adress, the other is the hotel name and the third is the hotel description. The hotel description is placed in the placeholder inp and that is what we feed inside thr prompt to create our first basic description. This is the passed inside the anti ai prompt and in the last step we change the hotel name and hotel adress based on what hotel we are dealing with. This is the basic architecture of what is happening over here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights_prompt=\"\"\"\n",
    "Generate concise bullet point highlights for a hotel booking website's hotel descriptions, emphasizing amenities, distances (in kilometers) from the airport and railway station, and proximity to tourist attractions. Cater to both casual and business travelers. \n",
    "Consider a mix of hotels, including luxury, boutique, and budget options. \n",
    "Highlight key amenities like free Wi-Fi, workspaces, fitness centers, and restaurants. \n",
    "Specify distances from the nearest airport and railway station. If unable to find metrics in the description then do not mention them in the highlights.\n",
    "Mention nearby tourist attractions. Identify unique selling points for each hotel. \n",
    "Keep the total word limit to 100 words.\n",
    "Example of how the highlights is supposed to look:\n",
    "• Located within a 10-minute drive of Baga Beach and Baga Night Market\n",
    "• Offers 44 guestrooms with minibars, flat-screen TVs, and free Wi-Fi\n",
    "• Full-service spa with massages, body treatments, and facials\n",
    "Highlights need to be generated for this article: {inp}  \n",
    "\"\"\"\n",
    "highlights_template=PromptTemplate(input_variables=[\"inp\"],template=highlights_prompt)\n",
    "highlights_runnable = highlights_template | llm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we are running two chains. One chain comprises of 3 intrinsic chains (chain_1 chain_2 chain_3) and the other is running paralle to these. we are using the modle llm3 defined earlier for the highlights prompt and llm for the first description,anti, and seo optimised write prompts chain. The same is coded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_1 = description_writer_template | llm | description_output_parser | {\"description\": RunnablePassthrough()}\n",
    "chain_2 = {\"description\": chain_1} | anti_ai_detection_template | llm | {\"anti_ai\":RunnablePassthrough()}\n",
    "chain_3 = {\"anti_ai\":chain_2, \"hotel_name\":itemgetter(\"hotel_name\"), \"address\":itemgetter(\"address\")} | seo_template | llm\n",
    "overall_chain = RunnableParallel(seo=chain_3,highlights=highlights_runnable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over here we just define the hotel path consistng of a relative and aboslute path. we read the excel file into the 3 main variables that is inp, adress and hotel name. The prompt generates generic desciptions and in the last step pf the langchain replaces hotel name and hotel adress with the relevant data corresponding to the hotel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = \"D:\\Suresh\\Hotel descriptions\\Input\"\n",
    "relative_path = f\"hoteldetails_{filenum}.xlsx\"\n",
    "absolute_path= os.path.join(cwd, relative_path)\n",
    "temp_data=pd.read_excel(absolute_path)\n",
    "temp_data.rename(columns={'basicInfo.description':'inp','locationInfo.address':'address','hotelName':'hotel_name'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our each excel file consisted over 4000 hoetl details. Since we have a toke limit of 10k tokens in gpt-4 and 60k tokens in \n",
    "gpt-3.5 we cant run in batches of 30 for gpt-4. Batches of 30 means the code runs descriptions of 30 hotels at once. \n",
    "Remember 1000 words corresponds to approximately 750 tokens. Over here we have batch size 30 and we run it for a specific number of batches of batches, and we divide out temp-data dataset in some number of batches which is denoted by len(batches). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=30\n",
    "batches=[temp_data[i:i+batch_size] for i in range(0,temp_data.shape[0],batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=588\n",
    "end=len(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code snippet is used for formatting purposes while appending our answers or response to our final file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_page(page,cityName,countryName,hotelId,hotelName):\n",
    "    temp={}\n",
    "    temp['cityName']=cityName\n",
    "    temp['countryName']=countryName\n",
    "    temp['hotelId']=hotelId\n",
    "    temp['hotelName']=hotelName\n",
    "    temp['new_description']=json.loads(page[\"seo\"].content)['response']\n",
    "    temp['highlights']=page['highlights'].content\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over here we first import tqdm library which is used for tqdm is a Python library that provides a simple and intuitive way to \n",
    "add progress bars to your code. It allows you to visualize the progress of iterative processes, showing how much work has been\n",
    "completed and how much remains. We first define 2 new columns in our temp_data frame. The 2 columns are called'new_descriptions'and 'highlights'. Post this we again define the folder path and file name in order to define an aboslute path to my output file. \n",
    "If the output file does not already exist in my system then it creates one, subsequently printing a message saying the corresponding file has been generated in the system.\n",
    "\n",
    "Post this we iterate over the number of batches and for each batch dataframe we create a list of dictionaries. Each dictinoary\n",
    "corresponds to a data point or row of the batch. Then we use overall chain which we used above to create descriptions of our hotels. Pos then we do formatting and update our information in the excel file. Thats it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f6e3f7939a4940bcd50ff74a3809d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589th batch started\n",
      "589th batch finished successfully\n",
      "590th batch started\n",
      "590th batch finished successfully\n",
      "591th batch started\n",
      "591th batch finished successfully\n",
      "592th batch started\n",
      "592th batch finished successfully\n",
      "593th batch started\n",
      "593th batch finished successfully\n",
      "594th batch started\n",
      "594th batch finished successfully\n",
      "595th batch started\n",
      "595th batch finished successfully\n",
      "596th batch started\n",
      "596th batch finished successfully\n",
      "597th batch started\n",
      "597th batch finished successfully\n",
      "598th batch started\n",
      "598th batch finished successfully\n",
      "599th batch started\n",
      "599th batch finished successfully\n",
      "600th batch started\n",
      "600th batch finished successfully\n",
      "601th batch started\n",
      "601th batch finished successfully\n",
      "602th batch started\n",
      "602th batch finished successfully\n",
      "603th batch started\n",
      "603th batch finished successfully\n",
      "604th batch started\n",
      "604th batch finished successfully\n",
      "605th batch started\n",
      "605th batch finished successfully\n",
      "606th batch started\n",
      "606th batch finished successfully\n",
      "607th batch started\n",
      "607th batch finished successfully\n",
      "608th batch started\n",
      "608th batch finished successfully\n",
      "609th batch started\n",
      "609th batch finished successfully\n",
      "610th batch started\n",
      "610th batch finished successfully\n",
      "611th batch started\n",
      "611th batch finished successfully\n",
      "612th batch started\n",
      "612th batch finished successfully\n",
      "613th batch started\n",
      "613th batch finished successfully\n",
      "614th batch started\n",
      "614th batch finished successfully\n",
      "615th batch started\n",
      "615th batch finished successfully\n",
      "616th batch started\n",
      "616th batch finished successfully\n",
      "617th batch started\n",
      "617th batch finished successfully\n",
      "618th batch started\n",
      "618th batch finished successfully\n",
      "619th batch started\n",
      "619th batch finished successfully\n",
      "620th batch started\n",
      "620th batch finished successfully\n",
      "621th batch started\n",
      "621th batch finished successfully\n",
      "622th batch started\n",
      "622th batch finished successfully\n",
      "623th batch started\n",
      "623th batch finished successfully\n",
      "624th batch started\n",
      "624th batch finished successfully\n",
      "625th batch started\n",
      "625th batch finished successfully\n",
      "626th batch started\n",
      "626th batch finished successfully\n",
      "627th batch started\n",
      "627th batch finished successfully\n",
      "628th batch started\n",
      "628th batch finished successfully\n",
      "629th batch started\n",
      "629th batch finished successfully\n",
      "630th batch started\n",
      "630th batch finished successfully\n",
      "631th batch started\n",
      "631th batch finished successfully\n",
      "632th batch started\n",
      "632th batch finished successfully\n",
      "633th batch started\n",
      "633th batch finished successfully\n",
      "634th batch started\n",
      "634th batch finished successfully\n",
      "635th batch started\n",
      "635th batch finished successfully\n",
      "636th batch started\n",
      "636th batch finished successfully\n",
      "637th batch started\n",
      "637th batch finished successfully\n",
      "638th batch started\n",
      "638th batch finished successfully\n",
      "639th batch started\n",
      "639th batch finished successfully\n",
      "640th batch started\n",
      "640th batch finished successfully\n",
      "641th batch started\n",
      "641th batch finished successfully\n",
      "642th batch started\n",
      "642th batch finished successfully\n",
      "643th batch started\n",
      "643th batch finished successfully\n",
      "644th batch started\n",
      "644th batch finished successfully\n",
      "645th batch started\n",
      "645th batch finished successfully\n",
      "646th batch started\n",
      "646th batch finished successfully\n",
      "647th batch started\n",
      "647th batch finished successfully\n",
      "648th batch started\n",
      "648th batch finished successfully\n",
      "649th batch started\n",
      "649th batch finished successfully\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "temp_data['new_description']=None\n",
    "temp_data['highlights']=None\n",
    "\n",
    "folder_path = fr\"D:\\Suresh\\Hotel descriptions\\Output\" # specify the relative folder path here\n",
    "file_name = f'hoteldetails_output_{filenum}.xlsx'\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    df = pd.DataFrame(columns=temp_data.columns)\n",
    "    df.to_excel(file_path, index=False)\n",
    "    print(f\"{file_name} created in {os.path.abspath(folder_path)}\")\n",
    "\n",
    "for i in tqdm(range(start,end)):\n",
    "    answers=pd.read_excel(file_path)\n",
    "    print(f\"{i+1}th batch started\")\n",
    "    batch=batches[i]\n",
    "    list_of_dicts=batch.to_dict('records')\n",
    "    duty_free_pages=overall_chain.batch(list_of_dicts)\n",
    "    for j in range(len(duty_free_pages)):\n",
    "        brand=list_of_dicts[j]['cityName']\n",
    "        category=list_of_dicts[j]['countryName']\n",
    "        product_name=list_of_dicts[j]['hotelId']\n",
    "        description=list_of_dicts[j]['hotel_name']\n",
    "        final_page=format_page(duty_free_pages[j],brand,category,product_name,description)\n",
    "        answers.loc[len(answers)]=final_page\n",
    "    answers.to_excel(file_path,index=False)\n",
    "    print(f\"{i+1}th batch finished successfully\")\n",
    "    start+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
